import os
import streamlit as st
import pandas as pd
import yfinance as yf
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import GradientBoostingRegressor
import numpy as np
import datetime
from concurrent.futures import ThreadPoolExecutor
from pandas.api.types import is_datetime64tz_dtype

# ---------------------------
# Set page configuration
# ---------------------------
st.set_page_config(
    page_title="Global Banks Performance Tracker",  # Default title in English
    layout="wide",
    page_icon="ðŸ¦"
)

# ---------------------------
# Language selection
# ---------------------------
if "language" not in st.session_state:
    st.session_state.language = "English"

language = st.sidebar.radio("Select Language / Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©", ["English", "Arabic"], index=["English", "Arabic"].index(st.session_state.language))
st.session_state.language = language

if language == "Arabic":
    L = {
        "page_title": "Ù…ØªØªØ¨Ø¹ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØµØ§Ø±Ù Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©",
        "app_title": "Ù…ØªØªØ¨Ø¹ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØµØ§Ø±Ù Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©",
        "app_description": ("ÙŠÙ‚Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ 30 Ù…ØµØ±ÙÙ‹Ø§ Ù…Ø§Ù„ÙŠÙ‹Ø§ Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø§Ù„Ù…Ø§Ø¶ÙŠØ©.\n\n"
                            "**Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** Yahoo Finance\n"
                            "**Ø§Ù„ØªØ·Ø¨ÙŠØ¹:** ÙŠØªÙ… ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù‚ÙŠØ§Ø³ MinMax Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©.\n"
                            "_Ù…Ø±Ø± Ø§Ù„Ù…Ø¤Ø´Ø± ÙÙˆÙ‚ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„._"),
        "filter_options": "Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµÙÙŠØ©",
        "select_company": "Ø§Ø®ØªØ± Ù…ØµØ±ÙÙ‹Ø§:",
        "select_date_range": "Ø§Ø®ØªØ± Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®:",
        "data_last_30": "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¢Ø®Ø± 30 ÙŠÙˆÙ…Ù‹Ø§)",
        "stock_price": "Ø³Ø¹Ø± Ø§Ù„Ø³Ù‡Ù…",
        "normalized_comparison": "Ù…Ù‚Ø§Ø±Ù†Ø© Ø³Ø¹Ø± Ø§Ù„Ø³Ù‡Ù… Ø§Ù„Ù…ÙØ·Ø¨Ø¹",
        "efficiency_comparison": "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒÙØ§Ø¡Ø©",
        "load_efficiency": "ØªØ­Ù…ÙŠÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒÙØ§Ø¡Ø©",
        "kpi": "Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "num_companies": "Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø±Ù",
        "average_growth_rate": "Ù…ØªÙˆØ³Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ",
        "top_growing_company": "Ø§Ù„Ù…ØµØ±Ù Ø°Ùˆ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø£Ø¹Ù„Ù‰",
        "summary": "Ù…Ù„Ø®Øµ",
        "summary_text": ("ÙŠÙˆÙØ± Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ 30 Ù…ØµØ±ÙÙ‹Ø§ Ù…Ø§Ù„ÙŠÙ‹Ø§ Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø§Ù„Ù…Ø§Ø¶ÙŠØ©ØŒ "
                         "Ø­ÙŠØ« ÙŠÙ‚Ø¯Ù… Ø£Ø¯ÙˆØ§Øª ØªÙØ§Ø¹Ù„ÙŠØ© Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ØŒ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ØŒ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©. "
                         "ÙŠØ¯Ø¹Ù… Ù‡Ø°Ø§ Ø§Ù„Ù†Ù‡Ø¬ Ø§Ù„Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø©."),
        "ml_section": "Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ÙˆØ§Ù„ØªÙˆØµÙŠØ©",
        "ml_forecast": "ØªÙˆÙ‚Ø¹ Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ù„Ù„ÙŠÙˆÙ… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Gradient Boosting Regression",
        "recommendation_buy": "Ø§Ù„ØªÙˆØµÙŠØ©: Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù†Ù…ÙˆØŒ ÙŠÙÙ†ØµØ­ Ø¨Ø´Ø±Ø§Ø¡ Ø³Ù‡Ù…",
        "recommendation_sell": "Ø§Ù„ØªÙˆØµÙŠØ©: Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù†Ù…ÙˆØŒ ÙŠÙÙ†ØµØ­ Ø¨Ø¨ÙŠØ¹ Ø³Ù‡Ù…",
        "note": "Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØ¹ØªÙ…Ø¯ Ù‡Ø°Ø§ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Gradient Boosting Ù…Ø¹ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªØ£Ø®Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ ÙˆÙŠÙØ³ØªØ®Ø¯Ù… Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ ÙÙ‚Ø·. ÙŠÙÙ†ØµØ­ Ø¨Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù‚Ø¨Ù„ Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ©.",
        "single_day_warning": "Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø®ØªØ§Ø± Ù‡Ùˆ ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯. Ù‚Ø¯ Ù„Ø§ ØªØ¹Ø±Ø¶ Ø¨Ø¹Ø¶ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø°Ø§Øª Ù…ØºØ²Ù‰.",
        "info_efficiency": "Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø²Ø± Ø£Ø¹Ù„Ø§Ù‡ Ù„ØªØ­Ù…ÙŠÙ„ Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒÙØ§Ø¡Ø©."
    }
else:
    L = {
        "page_title": "Global Banks Performance Tracker",
        "app_title": "Global Banks Performance Tracker",
        "app_description": ("This application provides a comprehensive analysis of the performance of the top 30 global banks over the past three years.\n\n"
                            "**Data Source:** Yahoo Finance\n"
                            "**Normalization:** Prices are normalized using MinMax scaling for comparison purposes.\n"
                            "_Hover over labels for more details._"),
        "filter_options": "Filter Options",
        "select_company": "Select a bank:",
        "select_date_range": "Select date range:",
        "data_last_30": "Data (Last 30 Days)",
        "stock_price": "Stock Price",
        "normalized_comparison": "Normalized Stock Price Comparison",
        "efficiency_comparison": "Efficiency Comparison",
        "load_efficiency": "Load Efficiency Comparison",
        "kpi": "Key Performance Indicators",
        "num_companies": "Number of Banks",
        "average_growth_rate": "Average Growth Rate",
        "top_growing_company": "Top Growing Bank",
        "summary": "Summary",
        "summary_text": ("This application provides a comprehensive overview of the performance of the top 30 global banks over the past three years, "
                         "offering interactive tools for exploring market data, comparing performance, and extracting key growth indicators. "
                         "This data-driven approach supports informed investment decisions."),
        "ml_section": "Machine Learning Forecast & Recommendation",
        "ml_forecast": "Forecasting Next Day's Closing Price using Gradient Boosting Regression",
        "recommendation_buy": "Buy Recommendation: Based on the forecast, consider buying",
        "recommendation_sell": "Sell Recommendation: Based on the forecast, consider selling",
        "note": "Note: This ML forecast uses a Gradient Boosting Regressor with lag features and should be used for demonstration purposes only. Further analysis is recommended before making investment decisions.",
        "single_day_warning": "Selected date range is a single day. Some charts might not display meaningful trends.",
        "info_efficiency": "Click the button above to load the Efficiency Comparison chart."
    }

# ---------------------------
# Data fetching function
# ---------------------------
@st.cache_data(show_spinner="Fetching data from Yahoo Finance...")
def fetch_data_yahoo(ticker):
    try:
        stock = yf.Ticker(ticker)
        data = stock.history(period="3y")
        data.reset_index(inplace=True)
        # Use a robust check for timezone awareness
        if not is_datetime64tz_dtype(data["Date"]):
            data["Date"] = data["Date"].dt.tz_localize("UTC")
        data["Date"] = data["Date"].dt.tz_convert("America/New_York")
        return data
    except Exception as e:
        st.error(f"Error fetching data from Yahoo Finance for {ticker}: {e}")
        return pd.DataFrame()

def fetch_all_data(tickers):
    with ThreadPoolExecutor() as executor:
        results = list(executor.map(fetch_data_yahoo, tickers))
    return {ticker: df for ticker, df in zip(tickers, results) if not df.empty}

# ---------------------------
# Preprocessing function
# ---------------------------
def preprocess_data(data_dict, start_date, end_date):
    df_all = pd.concat(
        [df.assign(Company=ticker) for ticker, df in data_dict.items()],
        ignore_index=True
    )
    # Filter the combined DataFrame by the selected date range
    df_filtered = df_all[(df_all["Date"] >= start_date) & (df_all["Date"] <= end_date)].copy()
    scaler = MinMaxScaler()
    df_filtered.loc[:, "Close_Scaled"] = scaler.fit_transform(df_filtered[["Close"]])
    return df_filtered

# ---------------------------
# Machine Learning Forecast
# ---------------------------
def ml_forecast(data_dict, start_date, end_date):
    forecast_results = {}
    for ticker, df in data_dict.items():
        # Filter each bank's data based on the selected date range
        df_ml = df.copy()
        df_ml = df_ml[(df_ml["Date"] >= start_date) & (df_ml["Date"] <= end_date)]
        df_ml.sort_values("Date", inplace=True)
        if df_ml.empty or df_ml.shape[0] < 10:
            continue
        
        # Create lag feature and convert dates for regression
        df_ml["Date_ordinal"] = df_ml["Date"].apply(lambda x: x.timestamp())
        df_ml["Close_lag1"] = df_ml["Close"].shift(1)
        df_ml = df_ml.dropna(subset=["Date_ordinal", "Close", "Close_lag1"])
        if df_ml.shape[0] < 10:
            continue
        
        X = df_ml[["Date_ordinal", "Close_lag1"]].values
        y = df_ml["Close"].values
        
        model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
        model.fit(X, y)
        
        last_date_ordinal = df_ml["Date_ordinal"].iloc[-1]
        last_close = df_ml["Close"].iloc[-1]
        # Predict next day: adding 86400 seconds (one day)
        X_next = np.array([[last_date_ordinal + 86400, last_close]])
        predicted_price = model.predict(X_next)[0]
        predicted_growth = (predicted_price - last_close) / last_close
        forecast_results[ticker] = predicted_growth
    
    return forecast_results

# ---------------------------
# Main Application
# ---------------------------
def main():
    st.title(L["app_title"])
    st.markdown(L["app_description"])

    # Full names of top 30 global banks
    banks_full = {
        "JPM": "JPMorgan Chase & Co.",
        "BAC": "Bank of America Corporation",
        "WFC": "Wells Fargo & Company",
        "C": "Citigroup Inc.",
        "HSBC": "HSBC Holdings plc",
        "GS": "The Goldman Sachs Group, Inc.",
        "MS": "Morgan Stanley",
        "UBS": "UBS Group AG",
        "DB": "Deutsche Bank AG",
        "BNP.PA": "BNP Paribas SA",
        "SAN": "Banco Santander, S.A.",
        "ING": "ING Groep N.V.",
        "BBVA": "Banco Bilbao Vizcaya Argentaria, S.A.",
        "CS": "Credit Suisse Group AG",
        "BCS": "Barclays PLC",
        "RY": "Royal Bank of Canada",
        "TD": "The Toronto-Dominion Bank",
        "BNS": "The Bank of Nova Scotia",
        "BMO": "Bank of Montreal",
        "CIB": "BanColombia S.A.",
        "ITUB": "ItaÃº Unibanco Holding S.A.",
        "BSBR": "Banco Santander (Brasil) S.A.",
        "BBD": "Banco Bradesco S.A.",
        "HDB": "HDFC Bank Limited",
        "ICICIBC.NS": "ICICI Bank Limited",
        "AXP": "American Express Company",
        "COF": "Capital One Financial Corporation",
        "USB": "U.S. Bancorp",
        "PNC": "The PNC Financial Services Group, Inc.",
        "STT": "State Street Corporation"
    }

    # Fetch data for all banks
    tickers = list(banks_full.keys())
    with st.spinner("Fetching data..."):
        data_dict = fetch_all_data(tickers)

    if not data_dict:
        st.error("No data available for the selected banks.")
        st.stop()

    # Sidebar filters
    st.sidebar.header(L["filter_options"])
    available_tickers = sorted(data_dict.keys())
    display_names = [f"{ticker} - {banks_full.get(ticker, '')}" for ticker in available_tickers]
    selected_display = st.sidebar.selectbox(L["select_company"], display_names)
    selected_ticker = selected_display.split(" - ")[0]

    # Determine the overall min and max dates from the fetched data
    min_date = pd.to_datetime(min(df["Date"].min() for df in data_dict.values())).date()
    max_date = pd.to_datetime(max(df["Date"].max() for df in data_dict.values())).date()
    date_range = st.sidebar.date_input(L["select_date_range"], [min_date, max_date])
    # Convert the selected dates to timezone-aware datetime objects using a list comprehension
    start_date, end_date = [pd.to_datetime(date).tz_localize("America/New_York") for date in date_range]

    # Preprocess data based on the selected date range
    df_filtered = preprocess_data(data_dict, start_date, end_date)

    if start_date == end_date:
        st.warning(L["single_day_warning"])

    # Filter the data for the selected ticker for display
    ticker_data_filtered = df_filtered[df_filtered["Company"] == selected_ticker]
    st.subheader(f"{selected_ticker} - {banks_full.get(selected_ticker, '')} {L['data_last_30']}")
    if not ticker_data_filtered.empty:
        st.dataframe(ticker_data_filtered.tail(30))
    else:
        st.info("No data available for the selected date range.")

    st.subheader(f"{selected_ticker} - {banks_full.get(selected_ticker, '')} {L['stock_price']}")
    fig_line = px.line(
        data_dict[selected_ticker],
        x="Date",
        y="Close",
        title=f"{selected_ticker} {L['stock_price']}",
        labels={"Close": L["stock_price"], "Date": "Date"}
    )
    st.plotly_chart(fig_line, use_container_width=True)

    st.subheader(L["normalized_comparison"])
    fig_compare = px.line(
        df_filtered,
        x="Date",
        y="Close_Scaled",
        color="Company",
        title=L["normalized_comparison"],
        labels={"Close_Scaled": L["normalized_comparison"], "Date": "Date"}
    )
    st.plotly_chart(fig_compare, use_container_width=True)

    if st.button(L["load_efficiency"]):
        st.subheader(L["efficiency_comparison"])
        efficiency_df = df_filtered.groupby("Company")["Close_Scaled"].mean().reset_index()
        efficiency_df = efficiency_df.sort_values(by="Close_Scaled", ascending=False)
        fig_bar = px.bar(
            efficiency_df,
            x="Company",
            y="Close_Scaled",
            title="Average Normalized Stock Price per Bank",
            labels={"Close_Scaled": "Average Normalized Price", "Company": "Bank"},
            color="Close_Scaled",
            color_continuous_scale="viridis"
        )
        st.plotly_chart(fig_bar, use_container_width=True)
    else:
        st.info(L["info_efficiency"])

    # Machine Learning Forecast and Recommendation
    with st.expander(L["ml_section"], expanded=False):
        st.markdown(f"#### {L['ml_forecast']}")
        forecast_results = ml_forecast(data_dict, start_date, end_date)
        if forecast_results:
            forecast_df = pd.DataFrame.from_dict(forecast_results, orient="index", columns=["Predicted Growth Rate"])
            forecast_df.sort_values(by="Predicted Growth Rate", ascending=False, inplace=True)
            forecast_df["Predicted Growth Rate (%)"] = forecast_df["Predicted Growth Rate"] * 100
            st.dataframe(forecast_df[["Predicted Growth Rate (%)"]].style.format("{:.2f}"))
            
            best_ticker = forecast_df.index[0]
            best_growth = forecast_df.iloc[0]["Predicted Growth Rate (%)"]
            worst_ticker = forecast_df.index[-1]
            worst_growth = forecast_df.iloc[-1]["Predicted Growth Rate (%)"]

            st.success(f"**{L['recommendation_buy']} {best_ticker} - {banks_full.get(best_ticker, '')}** with a predicted growth of {best_growth:.2f}%.")
            st.error(f"**{L['recommendation_sell']} {worst_ticker} - {banks_full.get(worst_ticker, '')}** with a predicted growth of {worst_growth:.2f}%.")
        else:
            st.warning("Insufficient data for machine learning forecast.")
        
        st.info(L["note"])

    # Add credit line with updated spelling for the name
    st.markdown("<center><small>Designed by Chief Engineer Tareq Majeed alkarimi - Iraqi Ministry of Oil</small></center>", unsafe_allow_html=True)

# Run the app
if __name__ == "__main__":
    main()
